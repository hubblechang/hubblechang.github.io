---
title: 滴滴
categories: 
- 面试
---
# Redis里存哪些数据
1. 秒杀业务相关的数据，如秒杀商品的信息
2. 经常访问的数据，比如商品页
3. 需要共享锁保证一致性的数据，比如商品的库存

# Redis的两种持久化
RDB和AOF
## RDB
Redis 可以通过创建快照来获得存储在内存里面的数据在 某个时间点 上的副本。Redis 创建快照之后，可以对快照进行备份，可以将快照复制到其他服务器从而创建具有相同数据的服务器副本（Redis 主从结构，主要用来提高 Redis 性能），还可以将快照留在原地以便重启服务器的时候使用。
## AOF
开启 AOF 持久化后每执行一条会更改 Redis 中的数据的命令，Redis 就会将该命令写入到 AOF 缓冲区 server.aof_buf 中，然后再写入到 AOF 文件中（此时还在系统内核缓存区未同步到磁盘），最后再根据持久化方式（ fsync策略）的配置来决定何时将系统内核缓存区的数据同步到硬盘中的。

1. 命令追加（append）：所有的写命令会追加到 AOF 缓冲区中。
2. 文件写入（write）：将 AOF 缓冲区的数据写入到 AOF 文件中。这一步需要调用write函数（系统调用），write将数据写入到了系统内核缓冲区之后直接返回了（延迟写）。注意！！！此时并没有同步到磁盘。
3. 文件同步（fsync）：AOF 缓冲区根据对应的持久化方式（ fsync 策略）向硬盘做同步操作。这一步需要调用 fsync 函数（系统调用）， fsync 针对单个文件操作，对其进行强制硬盘同步，fsync 将阻塞直到写入磁盘完成后返回，保证了数据持久化。
4. 文件重写（rewrite）：随着 AOF 文件越来越大，需要定期对 AOF 文件进行重写，达到压缩的目的。
5. 重启加载（load）：当 Redis 重启时，可以加载 AOF 文件进行数据恢复。


# 除了令牌桶之外的其他限流算法

常见的有三类，分别是计数器算法、漏桶算法、令牌桶算法

1. 计数器算法
    在一段时间间隔内（时间窗/时间区间），处理请求的最大数量固定，超过部分不做处理。

    比如：redis设置一个量，然后设置刷新时间，每处理一个请求减1

2. 漏桶算法
    漏桶算法限流的基本原理为：水（对应请求）从进水口进入到漏桶里，漏桶以一定的速度出水（请求放行），当水流入速度过大，桶内的总水量大于桶容量会直接溢出，请求被拒绝。

    在生产者消费者中间添加一个存储的桶，以一定的速率放行请求。

3. 令牌桶算法
    令牌桶算法的原理是系统会以一个恒定的速度往桶里放入令牌，而如果请求需要被处理，则需要先从桶里获取一个令牌，当桶里没有令牌可取时，则拒绝服务。

    感觉和漏桶的区别就是一个直接放进桶里，从而不保证桶会不会爆掉；令牌桶是拿到令牌的才有资格进桶，放进桶里的请求一定被处理

# 了不了解其他的MQ，对比他们的优缺点

重点关注支持的协议、消息存储、负载均衡、集群、订阅形式、消息回溯等。
|         | **RabbitMQ**                 | **Kafka**                    | **RocketMQ**           | **ZeroMQ**           | **ActiveMQ**                  |
|---------------|------------------------------|------------------------------|------------------------|----------------------|-------------------------------|
| **资料文档**      | 多                            | 中等                           | 少                      | 少                    | 多                             |
| **开发语言**      | Erlang                       | Scala                        | Java                   | C语言                  | Java                          |
| **支持的协议**     | AMQP                         | 自定义（基于TCP）                   | 自定义                    | TCP、UDP              | OpenWire、STOMP、REST、XMPP、AMQP |
| **消息存储**      | 内存、磁盘；支持少量堆积                 | 内存、磁盘、数据库；支持大量堆积             | 磁盘；支持大量堆积              | 消息发送端的内存或者磁盘中；不支持持久化 | 内存、磁盘、数据库；支持少量堆积              |
| **消息事务**      | 支持                           | 支持                           | 支持                     | 不支持                  | 支持                            |
| **负载均衡**      | 支持的不好                        | 支持                           | 支持                     | 去中心化，不支持负载均衡         | 可基于zookeeper实现负载均衡            |
| **集群方式**      | 支持简单集群 对高级集群模式支持不好           | 天然的‘Leader-Slave’无状态集群       | 常用 多对'Master-Slave' 模式 | 去中心化，不支持集群           | 支持简单集群模式对高级集群模式支持不好           |
| **管理界面**      | 好                            | 一般                           | 有管理后台                  | 无                    | 一般                            |
| **可用性**       | 高（主从）                        | 非常高（分布式）                     | 非常高（分布式）               | 高                    | 高（主从）                         |
| **消息重复**      | 支持at least once、at most once | 支持at least once、at most once | 支持at least once        | 只有重传机制，但是没有持久化       | 支持at least once               |
| **吞吐量TPS**    | 比较大                          | 极大                           | 大                      | 极大                   | 比较大                           |
| **订阅形式和消息分发** | direct、topic、Headers和fanout  | 发布订阅模式                       | 发布订阅模式                 | 点对点(p2p)             | 点对点(p2p)、广播（发布-订阅）            |
| **顺序消息**      | 不支持                          | 支持                           | 支持                     | 不支持                  | 不支持                           |
| **消息确认**      | 支持                           | 支持                           | 支持                     | 支持                   | 支持                            |
| **消息回溯**      | 不支持                          | 支持指定分区offset位置的回溯            | 支持指定时间点的回溯             | 不支持                  | 不支持                           |
| **消息重试**      | 不支持                          | 不支持                          | 支持                     | 不支持                  | 不支持                           |
| **并发度**       | 并发度极高                        | 并发度高                         | 并发度高                   | 并发度高                 | 并发度高                          |


# 动态查询文件更新的命令
`tail -f xxxfile`

`tail -n 100 xxx.log`

# 热key问题有没有更优的更新策略
## 热key的监控
+ 根据业务经验，预估哪些是热key。
+ 在客户端收集。在操作redis之前，加上统计频次的逻辑，然后将统计数据发送给一个聚合计算的服务进行统计。
+ 在proxy层收集。有些服务在请求redis之前会请求一个proxy服务，这种场景可以使用在proxy层收集热key数据，收集机制类似于在客户端收集。
+ redis集群监控。如果出现某个实例qps倾斜，说明可能存在热key。
+ 执行redis-cli时加上–-hotkeys选项

## 热key的解决
### 增加实例

### 本地缓存

当热 Key 出现时，我们可以选择将其加载至系统的 JVM 中，以便后续针对这些热 Key 的请求能够直接从 JVM 中快速获取，无需再经过 Redis 层。在实现这一机制时，我们可以利用多种本地缓存工具，例如 Ehcache、Google Guava 中的 Cache 工具，或者简单地使用 HashMap 作为本地缓存工具。

+ 缺点：
    - 如果对所有热key进行本地缓存，那么本地缓存是否会过大，从而影响应用程序本身的性能开销。
    - 可能需要保证本地缓存和redis数据的一致性。

### 流量分散

将热key加上前缀或者后缀，把热key的数量从1个变成实例个数，利用分片特性将这n个key分散在不同节点上，这样就可以在访问的时候，采用客户端负载均衡的方式，随机选择一个key进行访问，将访问压力分散到不同的实例中。这个方案有个明显的缺点，就是缓存的维护成本大：假如有n为100，则更新或者删除key的时候需要操作100个key。

+ 全量更新：当热key的值发生变化时，更新所有分散在不同实例上的key。这种方法确保所有实例上的数据一致性，但更新操作较为耗时，可能会影响性能。

+ 通知更新：使用Redis的发布/订阅机制，当热key的值发生变化时，发布通知，订阅者收到通知后进行更新。这种方法实时性高，能够快速响应变化，但需要额外的发布/订阅机制，可能会增加系统的复杂性。

+ 定时同步：定期检查热key的值，如果发生变化，则进行更新。这种方法简单易实现，不需要实时响应，但数据同步可能会有延迟，不适用于对实时性要求高的场景。

+ 分布式锁：使用分布式锁来确保只有一个实例能够更新热key的值，其他实例在锁释放后获取最新的值。这种方法确保数据一致性，避免并发更新导致的数据不一致问题，但需要额外的分布式锁机制，可能会增加系统的复杂性。

